<div class="container">
  <div class="row me-row content-ct">
      <h2 class="row-title">About</h2>
      <div class="col-md feature">
        With the increasing prominence of human-agent interaction in hybrid teams in diverse industries, human-agent teamwork is no longer a
        topic of the future, but of the present. However, several challenges arise that still need
        to be addressed carefully. One of these challenges is understanding how trust is defined
        and how it functions in human-agent teams. Psychological literature suggests that within
        human teams, team members rely on trust to make decisions and to be willing to rely
        on their team. Moreover, the multi-agent systems (MAS) community has been adopting
        trust mechanisms to support decision-making of the agents regarding their peers and for
        delegating tasks to agents. Finally, in the last couple of years, researchers have been focusing on how humans trust AI agents and how such systems can be trustworthy. How-
        ever, bringing this knowledge on teams and trust together in a HI setting brings its own
        unique perspectives. When we think of a team composed of both humans and agents,
        with recurrent (or not) interactions, how do these all come together? Currently, we are
        missing approaches that integrate the prior literature on trust in teams in these different disciplines. In particular, when looking at dyadic or team-level trust relationships in
        such a team, we also need to look at how an AI should trust a human teammate. In this
        context, trust, or rather the factors that influence it, must be formally defined so that the
        AI can evaluate them, rather than using questionnaires at the end of a task, as is usually assessed in psychology. Furthermore, a humanâ€™s trust in an artificial team member,
        and vice-versa, will change over time, affecting the trust dynamics. In this workshop,
        we want to motivate the conversation across the different fields and domains. Together,
        we intend to shape the road to address these questions to guarantee a successful and  trustworthy human-AI agent teamwork

        With these premises, we are organizing the MULTITTRUST 4.0 workshop, which is part of the
        <a href="https://hhai-conference.org/2025/"  target="_blank" >HHAI conference 2025</a>. This is the third edition of the original
        <a href="https://multittrust.github.io/"  target="_blank" >MULTITRUST</a> workshop at the <a href="https://multittrust.github.io/"  target="_blank" >HHAI 2025 Conference in Pisa</a>
        Our goal is to motivate the conversation across the different fields and domains, and shape the road to
        answer these questions and more.
      </div>
    </div>
</div>



